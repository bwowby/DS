{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNXk5IOXtnxbTjulFFuSREH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bwowby/DS/blob/master/pytorch_tutorial/pytorch_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "008C91RGF37t"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "aTlnVpmZGQYh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        " Fashion-MNIST는 Zalando의 기사 이미지 데이터셋으로 60,000개의 학습 예제와 10,000개의 테스트 예제로 이루어져 있습니다.\n",
        " 각 예제는 흑백(grayscale)의 28x28 이미지와 10개 분류(class) 중 하나인 정답(label)으로 구성\n",
        "'''\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train = False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ],
      "metadata": {
        "id": "yrBzfSQtGnhm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54fece80-c045-43d2-ba7d-93e360faf8cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:03<00:00, 7685885.85it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 137908.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 2509959.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 11709477.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJUD1n65So6U",
        "outputId": "ec88a7c9-4dd4-421d-9c14-22c27c3eb184"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "UJqj2is5PMEB",
        "outputId": "16138f85-5913-4eb5-c680-b523ed8252eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# 데이터로더를 생성합니다.\n",
        "# 데이터 로더: 학습할 데이터셋을 쪼개서, 미니 배치 단위로 모델에 입력\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MweZIfxeHFFg",
        "outputId": "4dbdc97d-8ac8-415a-8a8b-39e25c3a0375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 학습에 사용할 CPU나 GPU, MPS 장치를 얻습니다.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "class NeuralNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10) # 10개를 출력\n",
        "        )\n",
        "\n",
        "    # 모델 인스턴스를 호출하면 forward가 실행됨 init -> call -> forward\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XSGsJHmHiKS",
        "outputId": "397de7f5-7e00-447c-d41e-0fed8da58b82"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eOSkbB7EOhuC",
        "outputId": "0bd98b89-e6f8-48ba-ea89-2b829faf1ea7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
        "optimizer = torch.optim.Adam(model.parameters()) # 데이터 셋이 엄청 클 때"
      ],
      "metadata": {
        "id": "k3zLNZLhHjRI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 예측 오류 계산\n",
        "        pred = model(X) # return 된 logits\n",
        "        loss = loss_fn(pred, y) # 크로스 엔트로피 내에서\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad() # 해당 옵티마이저에서 최적화하는 파라미터들의 그라디언트를 모두 0으로 만들어줍니다. (첫번째 레이어는 동작을 안함) rnn 구현에 필요함 -> 이건 pytorch\n",
        "        # model.zero_grad()\n",
        "\n",
        "        loss.backward()  # 텐서를 0으로 만들어주고 역전파를 시켜야 합니다.\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad(): # 성능 이슈, model.eval() 과 비슷 (batch norm)\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "dHmRXF-UHk4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 30\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IuDmSb8ZHl8b",
        "outputId": "da35f1a4-6b0f-4563-d949-2c12182eac29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 11\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 12\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 13\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 14\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 15\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 16\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 17\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 18\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 19\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 20\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 21\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 22\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 23\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 24\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 25\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 26\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 27\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 28\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 29\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Epoch 30\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 2.300287  [ 6464/60000]\n",
            "loss: 2.300375  [12864/60000]\n",
            "loss: 2.302827  [19264/60000]\n",
            "loss: 2.308887  [25664/60000]\n",
            "loss: 2.310579  [32064/60000]\n",
            "loss: 2.311097  [38464/60000]\n",
            "loss: 2.313778  [44864/60000]\n",
            "loss: 2.304050  [51264/60000]\n",
            "loss: 2.309954  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 10.5%, Avg loss: 2.304187 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZRYJpF4MTO1",
        "outputId": "fd09c02e-5c98-4836-f1c9-9fd4f9e958b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299303  [   64/60000]\n",
            "loss: 0.561448  [ 6464/60000]\n",
            "loss: 0.389172  [12864/60000]\n",
            "loss: 0.500570  [19264/60000]\n",
            "loss: 0.461002  [25664/60000]\n",
            "loss: 0.438441  [32064/60000]\n",
            "loss: 0.362635  [38464/60000]\n",
            "loss: 0.533398  [44864/60000]\n",
            "loss: 0.473495  [51264/60000]\n",
            "loss: 0.514458  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.5%, Avg loss: 0.421821 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 0.285353  [   64/60000]\n",
            "loss: 0.342019  [ 6464/60000]\n",
            "loss: 0.263849  [12864/60000]\n",
            "loss: 0.415824  [19264/60000]\n",
            "loss: 0.397172  [25664/60000]\n",
            "loss: 0.376030  [32064/60000]\n",
            "loss: 0.297115  [38464/60000]\n",
            "loss: 0.493398  [44864/60000]\n",
            "loss: 0.391807  [51264/60000]\n",
            "loss: 0.436020  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.1%, Avg loss: 0.395731 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 0.236045  [   64/60000]\n",
            "loss: 0.306096  [ 6464/60000]\n",
            "loss: 0.231247  [12864/60000]\n",
            "loss: 0.330148  [19264/60000]\n",
            "loss: 0.372551  [25664/60000]\n",
            "loss: 0.337523  [32064/60000]\n",
            "loss: 0.253741  [38464/60000]\n",
            "loss: 0.437238  [44864/60000]\n",
            "loss: 0.341697  [51264/60000]\n",
            "loss: 0.403599  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 85.5%, Avg loss: 0.397542 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 0.269679  [   64/60000]\n",
            "loss: 0.304060  [ 6464/60000]\n",
            "loss: 0.223436  [12864/60000]\n",
            "loss: 0.291205  [19264/60000]\n",
            "loss: 0.357861  [25664/60000]\n",
            "loss: 0.320457  [32064/60000]\n",
            "loss: 0.251883  [38464/60000]\n",
            "loss: 0.411204  [44864/60000]\n",
            "loss: 0.324852  [51264/60000]\n",
            "loss: 0.374336  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.3%, Avg loss: 0.374784 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 0.219973  [   64/60000]\n",
            "loss: 0.304079  [ 6464/60000]\n",
            "loss: 0.225027  [12864/60000]\n",
            "loss: 0.252568  [19264/60000]\n",
            "loss: 0.352905  [25664/60000]\n",
            "loss: 0.301065  [32064/60000]\n",
            "loss: 0.218495  [38464/60000]\n",
            "loss: 0.375884  [44864/60000]\n",
            "loss: 0.271104  [51264/60000]\n",
            "loss: 0.316729  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 86.8%, Avg loss: 0.357355 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"./model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw0QKGe1IGm_",
        "outputId": "8e2e7ccb-2c3a-426f-a8f2-ed079c4dccff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "model.load_state_dict(torch.load(\"./model.pth\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRP3V9fxIJZA",
        "outputId": "f950d0d6-c445-4f2f-99c0-a8c06bf4a229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I81RnsbEIJOF",
        "outputId": "545773db-3f7b-45fe-ef91-dcf2507a99a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-0wvPUvIKtV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}